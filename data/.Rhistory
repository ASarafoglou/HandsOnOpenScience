BFType = c('LogBFe0', 'LogBFr0', 'LogBFre'),
BF = c(LogBFe0, LogBFr0, LogBFre))
denominator <- sum(1, exp(-LogBFe0), exp(LogBFre))
post_probs <- data.frame(
Hyps = c('p(He | x)', 'p(H0 | x)', 'p(Hr | x)'),
Prob = c(1, exp(-LogBFe0), exp(LogBFre))/denominator)
post_probs
round(post_probs, 3)
post_probs
post_probs$Prob
round(post_probs$Prob)
round(post_probs$Prob, 3)
exp(2)
x
n
x/n
journals
x/n
x
n
library(plyr)
library(knitr)
knitr::include_graphics("scheme_multibridge.png", auto_pdf = TRUE)
library('multibridge')
# Observed counts
x <- c(509, 353, 177, 114,  77,  77,  53,  73,  64)
# Concentration parameters
a <-  rep(1, 9)
# Expected proportions for H_0 and H_r2
p0  <- log10((1:9 + 1)/1:9)
pr2 <- rep(1/9, 9)
# Execute the analysis
results_H0_He   <- mult_bf_equality(x = x, a = a, p = p0)
results_Hr2_He  <- mult_bf_equality(x = x, a = a, p = pr2)
logBFe0  <- results_H0_He$bf$LogBFe0
logBFer2 <- results_Hr2_He$bf$LogBFe0
# Observed counts
x <- c(509, 353, 177, 114,  77,  77,  53,  73,  64)
# Concentration parameters
a <-  rep(1, 9)
# Labels for categories of interest
factor_levels <- 1:9
# Specifying the informed hypotheses as a string
Hr1 <- c('1 > 2 > 3 > 4 > 5 > 6 > 7 > 8 > 9')
Hr3 <- c('1 > 2 = 3 = 4 = 5 = 6 = 7 > 8 > 9')
# Execute the analysis
results_He_Hr1 <- mult_bf_informed(x = x, Hr = Hr1, a = a,
factor_levels = factor_levels,
bf_type = 'LogBFer', seed = 2020)
logBFer1 <- summary(results_He_Hr1)$bf
results_He_Hr3 <- mult_bf_informed(x = x, Hr = Hr3, a = a,
factor_levels = factor_levels,
bf_type = 'LogBFer', seed = 2020)
logBFer3 <- summary(results_He_Hr3)$bf
bayes_factors <- data.frame(
BFType = c('LogBFe0', 'LogBFr10', 'LogBFr20', 'LogBFr30'),
LogBF  = c(logBFe0, -logBFer1 + logBFe0, -logBFer2 + logBFe0, -logBFer3 + logBFe0))
denominator <- sum(1, exp(-logBFe0), exp(-logBFer1), exp(-logBFer2), exp(-logBFer3))
post_probs <- data.frame(
Hyps = c('p(H0 | x)', 'p(He | x)', 'p(Hr1 | x)', 'p(Hr2 | x)', 'p(Hr3 | x)'),
Prob = c(1, exp(-logBFe0), exp(-logBFer1), exp(-logBFer2), exp(-logBFer3))/denominator)
post_probs
bayes_factors
c(logBFe0, logBFer1, logBFer2, logBFer3)
post_probs <- data.frame(
Hyps = c('p(H0 | x)', 'p(He | x)', 'p(Hr1 | x)', 'p(Hr2 | x)', 'p(Hr3 | x)'),
Prob = c(1, exp(logBFe0), exp(-logBFer1), exp(-logBFer2), exp(-logBFer3))/denominator)
post_probs
c(1, exp(-logBFe0), exp(-logBFer1), exp(-logBFer2), exp(-logBFer3))
exp(0)
c(1, exp(-logBFe0), exp(-logBFer1), exp(-logBFer2), exp(-logBFer3))/denominator)
c(1, exp(-logBFe0), exp(-logBFer1), exp(-logBFer2), exp(-logBFer3))/denominator
logBFe0
logBFer1
exp(logBFer1)
1/exp(logBFer1)
exp(logBFe0)
bayes_factors
denominator2 <- c(1, exp(bayes_factors$LogBF))
denominator2
denominator2/sum(denominator2)
post_probs
denominator <- sum(exp(-logBFe0), 1, exp(-logBFer1), exp(-logBFer2), exp(-logBFer3))
post_probs <- data.frame(
Hyps = c('p(H0 | x)', 'p(He | x)', 'p(Hr1 | x)', 'p(Hr2 | x)', 'p(Hr3 | x)'),
Prob = c(exp(-logBFe0), 1, exp(-logBFer1), exp(-logBFer2), exp(-logBFer3))/denominator)
post_probs$Prob
109+291+4
mean_diff <- 0.1028
se_diff <- 0.01257
mean_diff/se_diff
nrel <- 3489
nnrel <- 6664
install.packages('esci')
if (!is.element("esci", installed.packages()[,1])) {
devtools::install_github(repo = "rcalinjageman/esci")
}
library("esci")
estimate <- estimateStandardizedMeanDifference(m1 = 10,
m2 = 15,
s1 = 2,
s2 = 2,
n1 = 20,
n2 = 20,
conf.level = .95)
estimate
estimate <- estimateStandardizedMeanDifference(m1 = 3.73,
m2 = 3.63,
s1 = 2,
s2 = 2,
n1 = nrel,
n2 = 20,
conf.level = .95)
estimate
estimate <- estimateStandardizedMeanDifference(m1 = 3.73,
m2 = 3.63,
s1 = 0.001,
s2 = 0.001,
n1 = nrel,
n2 = nnrel,
conf.level = .95)
estimate
estimate <- estimateStandardizedMeanDifference(m1 = 3.73,
m2 = 3.63,
s1 = 0.01,
s2 = 0.01,
n1 = nrel,
n2 = nnrel,
conf.level = .95)
estimate
library(effectsize)
?r_to_d
r_to_d(0.007)
r_to_d(sqrt(0.007))
r_to_d(sqrt(0.007))
r_to_d(sqrt(0.0037))
r_to_d(sqrt(0.0099))
r_to_d(sqrt(0.0065))
?data.frame
L3 <- LETTERS[1:3]
fac <- sample(L3, 10, replace = TRUE)
(d <- data.frame(x = 1, y = 1:10, fac = fac))
## The "same" with automatic column names:
data.frame(1, 1:10, sample(L3, 10, replace = TRUE))
L3 <- LETTERS[1:3]
fac <- sample(L3, 10, replace = TRUE)
(d <- data.frame(x = 1, y = 1:10, fac = fac))
## The "same" with automatic column names:
dat <- data.frame(1, 1:10, sample(L3, 10, replace = TRUE))
dat
dat[4,]
dat[4,] <- NULL
?grepl
404 + 130 + 22 + 157
109 + 291 + 4
404 + 130 + 22 + 157
713 - 47 - 39
sample(1:2, 1)
?merge
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
library(rethinking)
library(rstan)
p_nodeviation_prereg
`r papaja::printnum(bayes_factors[1, 2], digits = 2)`
library(plyr)
library(knitr)
knitr::include_graphics("scheme_multibridge.png", auto_pdf = TRUE)
library('multibridge')
# Observed counts
x <- c(509, 353, 177, 114,  77,  77,  53,  73,  64)
# Concentration parameters
a <-  rep(1, 9)
# Expected proportions for H_0 and H_r2
p0  <- log10((1:9 + 1)/1:9)
pr2 <- rep(1/9, 9)
# Execute the analysis
results_H0_He   <- mult_bf_equality(x = x, a = a, p = p0)
results_Hr2_He  <- mult_bf_equality(x = x, a = a, p = pr2)
logBFe0  <- results_H0_He$bf$LogBFe0
logBFer2 <- results_Hr2_He$bf$LogBFe0
# Observed counts
x <- c(509, 353, 177, 114,  77,  77,  53,  73,  64)
# Prior specification for Dirichlet prior distribution under H_e
a <-  rep(1, 9)
# Labels for categories of interest
factor_levels <- 1:9
# Specifying the informed hypotheses as a string
Hr1 <- c('1 > 2 > 3 > 4 > 5 > 6 > 7 > 8 > 9')
Hr3 <- c('1 > 2 = 3 = 4 = 5 = 6 = 7 > 8 > 9')
# Execute the analysis
results_He_Hr1 <- mult_bf_informed(x = x, Hr = Hr1, a = a,
factor_levels = factor_levels,
bf_type = 'LogBFer', seed = 2020)
logBFer1 <- summary(results_He_Hr1)$bf
results_He_Hr3 <- mult_bf_informed(x = x, Hr = Hr3, a = a,
factor_levels = factor_levels,
bf_type = 'LogBFer', seed = 2020)
logBFer3 <- summary(results_He_Hr3)$bf
bayes_factors <- data.frame(
BFType = c('LogBFe0', 'LogBFr10', 'LogBFr20', 'LogBFr30'),
LogBF  = c(logBFe0, -logBFer1 + logBFe0, -logBFer2 + logBFe0, -logBFer3 + logBFe0))
denominator <- c(1, exp(bayes_factors$LogBF))
post_probs <- data.frame(
Hyps = c('p(H0 | x)', 'p(He | x)', 'p(Hr1 | x)', 'p(Hr2 | x)', 'p(Hr3 | x)'),
Prob = denominator/sum(denominator))
first_digits <- 1:9
benford <- log10((first_digits + 1) / first_digits)
plot(
summary(results_He_Hr1)
, xlab = "Leading digit"
# , ylab = "Proportion"
, main = ""
, panel.first = {
lines(x = first_digits, y = benford, lty = "22", col = grey(0.5))
points(x = first_digits, y = benford, pch = 16, col = "white", cex = 2)
points(x = first_digits, y = benford, pch = 16, bg = "white", col = grey(0.7), cex = 0.8)
}
)
points(x = first_digits, y = benford, pch = 16, bg = "white", col = grey(0.7), cex = 0.8)
legend(
"right"
, legend = c("Benford", "Posterior")
, col = c(grey(0.7), "black")
, pch = c(16, 21)
, pt.bg = c(NULL, "white")
, lty = c("22", "solid")
, lwd = c(1.25, 1)
, bty = "n"
, pt.cex = c(0.8, 1.5)
, title = "Distribution"
, seg.len = 1.5
)
data(journals)
# Since percentages are rounded to two decimal values, we round the
# articles with an error to obtain integer values
x <- round(journals$articles_with_NHST  *
(journals$perc_articles_with_errors/100))
# Total number of articles
n <- journals$articles_with_NHST
# Prior specification for beta prior distributions under H_e
a <- rep(1, 8)
b <- rep(1, 8)
# Labels for categories of interest
journal_names <- journals$journal
# Specifying the informed Hypothesis
Hr1 <- c('JAP = PS = JCCP = PLOS = DP = FP = JEPG < JPSP')
Hr2 <- c('JAP , PS , JCCP , PLOS , DP , FP , JEPG < JPSP')
# Execute the analysis for Hr1
results_H0_Hr1 <- binom_bf_informed(x = x, n = n, Hr = Hr1, a = a, b = b,
factor_levels = journal_names,
bf_type = 'LogBFr0', seed = 2020)
# Execute the analysis for Hr2
results_H0_Hr2 <- binom_bf_informed(x = x, n = n, Hr = Hr2, a = a, b = b,
factor_levels = journal_names,
bf_type = 'LogBFr0', seed = 2020)
LogBFe0  <- results_H0_Hr1$bf_list$bf0_table[['LogBFe0']]
LogBFr10 <- summary(results_H0_Hr1)$bf
LogBFr20 <- summary(results_H0_Hr2)$bf
LogBFr1e <- -results_H0_Hr1$bf_list$bfr_table[['LogBFer']]
LogBFr2e <- -results_H0_Hr2$bf_list$bfr_table[['LogBFer']]
bayes_factors <- data.frame(
BFType = c('LogBFe0', 'LogBFr10', 'LogBFr20'),
BF = c(LogBFe0, LogBFr10, LogBFr20))
denominator <- sum(1, exp(-LogBFe0), exp(LogBFr1e), exp(LogBFr2e))
post_probs <- data.frame(
Hyps = c('p(He | x)', 'p(H0 | x)', 'p(Hr1 | x)' , 'p(Hr2 | x)'),
Prob = c(1, exp(-LogBFe0), exp(LogBFr1e), exp(LogBFr2e))/denominator)
bayes_factors
post_probs
papaja::printnum(post_probs[3, 2], digits = 4, format = 'e')
papaja::printnum(post_probs[3, 2], digits = 4, format = 'f')
papaja::printnum(post_probs[1, 2], digits = 4, format = 'f')
papaja::printnum(post_probs[4, 2], digits = 4, format = 'f')
papaja::printnum(post_probs[1, 2], digits = 4, format = 'f')
papaja::printnum(post_probs[3, 2], digits = 4, format = 'e')
papaja::printnum(post_probs[2, 2], digits = 4, format = 'e')
bayes_factors
papaja::printnum(bayes_factors[3, 2], digits = 2, format = 'f')
papaja::printnum(bayes_factors[1, 2], digits = 2, format = 'f')
papaja::printnum(bayes_factors[2, 2], digits = 2, format = 'f')
papaja::printnum(bayes_factors[3, 2], digits = 2, format = 'f')
papaja::printnum(bayes_factors[1, 2], digits = 2, format = 'f')
LogBFr2e
papaja::printnum(LogBFr2e, digits=2, format = 'f')
`r papaja::printnum(post_probs[1, 2], digits = 4, format = 'f')`
papaja::printnum(post_probs[1, 2], digits = 4, format = 'f')
papaja::printnum(post_probs[1, 2], digits = 3, format = 'f')
355/713
dat <- data.frame(id = 1:10, list_item = list(1:10), char_item = as.character(1:10))
dat
str(dat)
list(1:10)
str(dat)
head(dat)
1:10
as.list(1:10)
dat <- data.frame(id = 1:10, list_item = as.list(1:10), char_item = as.character(1:10))
head(dat)
sample(c('participation', 'importance'), 1)
.00045
sqrt(.00045)
library(effectsize)
?effectsize::F_to_eta2
F_to_eta2(f=36.541, df=2, df_error=10164, ci = 0.95)
effects <- F_to_eta2(f=36.541, df=2, df_error=10164, ci = 0.95)
effects$Eta2_partial
effects$CI_low
effects$CI_high
effects <- F_to_eta2(f=9.36, df=2, df_error=10161, ci = 0.95)
# RQ2
effects <- F_to_eta2(f=9.36, df=2, df_error=10161, ci = 0.95)
effects$Eta2_partial
effects$CI_low
effects$CI_high
effectsize::F_to_d(f=9.36, df=2, df_error=10161)
# RQ2
effects <- effectsize::F_to_eta2(f=9.36, df=2, df_error=10161, ci = 0.95)
effects$Eta2_partial
effects$CI_low
effects$CI_high
?F_to_eta2
sample(1:2, 1)
library(papaya)
library(papaja)
citation(papaja)
citation("papaja")
library(multibridge)
data(lifestresses)
?lifestresses
data(lifestresses)
# Prior specification
# We assign a uniform Dirichlet distribution, that is, we set all
# concentration parameters to 1
a             <- rep(1, 18)
x             <- lifestresses$stress.freq
factor_levels <- lifestresses$month
# Test the following restricted Hypothesis:
# Hr: month1 > month2 > ... > month18
Hr            <- paste0(1:18, collapse=">"); Hr
out  <- mult_bf_informed(x=x, Hr=Hr, a=a, factor_levels=factor_levels,
niter=1e3, bf_type = 'BFre', seed = 4)
m1 <- summary(out)
m1
plot(m1)
plot(m1, ylim = c(0, 0.3))
plot(m1, ylim = c(0, 0.2))
data(lifestresses)
# Prior specification
# We assign a uniform Dirichlet distribution, that is, we set all
# concentration parameters to 1
a             <- rep(1, 18)
x             <- lifestresses$stress.freq
factor_levels <- lifestresses$month
# Test the following restricted Hypothesis:
# Hr: month1 > month2 > ... > month18
Hr            <- paste0(1:18, collapse=">"); Hr
out  <- mult_bf_informed(x=x, Hr=Hr, a=a, factor_levels=factor_levels,
niter=1e3, bf_type = 'BFr0', seed = 4)
summary(out)
summary(m1)
plot(m1)
37/70
37/70 * 100
(37/70) * 100
37/70 * 72
24/70 * 72
40/70 * 72
23/70 * 55
23/70 * 65
35/70 * 55
35/70 * 65
42/73 * 65
42/73 * 55
(24/70)*70
(24/70)*100
(24/70)*72
(24/70)*77
(35/70)*77
(35/70)*72
(40/70)*72
(40/70)*77
source('~/Dropbox/Projects/Multinomial Project/Multibridge_SubmissionFiles/benfords_law.R', echo=TRUE)
source('~/Dropbox/Projects/Multinomial Project/Multibridge_SubmissionFiles/prevalence.R', echo=TRUE)
10/15
125/120
120/125
125 * .6666667
125/100
125/100 * 4
42/72
42/72 * 75
42/72 * 100
42/72 * 80
44/77 * 80
44/77 * 75
46/100 * 75
46/100 * 80
46*0.55
46*0.65
38*0.65
38*0.55
46*0.55
46*0.65
51/75
51/75 * 70
51/75 * 75
46/100 * 70
46/100 * 75
38/100 * 70
38/100 * 75
103 * 0.5
library(mvtnorm)
Z <- rmvnorm(9)
Z
?rmvnorm
Z <- rmvnorm(9, mean=c(0,0,0))
Z
Z <- rmvnorm(3, mean=c(0,0,0))
Z
U <- rmvnorm(3, mean=c(0,0,0))
U
corr(Z)
cor(Z)
Tzz <- cor(Z)
Tzz
t(Tzz)%*%Tzz
Rzz <- cor(Z)
Rzz
Rzz %*% t(Rzz)
Tzz <- Rzz %*% t(Rzz)
Tzz
Tzz %*% t(Tzz)
t(Tzz) %*% Tzz
t(Tzz) %/% Tzz
Tzz %/% Tzz
?mahalanobis
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
library(rethinking)
library(rstan)
#dat <- read.csv(file = 'dummydata.csv', header=T)
dat <- read.csv(file = 'stage2_blindingdata.csv', header=T)
str(dat)
dat$cond <- as.numeric(as.factor(dat$condition)) - 1
datalist <- list(N = nrow(dat),
y = dat$deviation)
m0 <- stan(file ="h4_m0.stan",
data = datalist,
iter = 10000,
warmup = 1000,
cores = 4)
datalist <- list(N = nrow(dat),
y = dat$deviation,
x = dat$cond)
m1 <- stan(file ="h4_m1.stan",
data = datalist,
iter = 10000,
warmup = 1000,
cores = 4)
m0_bridge <- bridgesampling::bridge_sampler(m0)
m1_bridge <- bridgesampling::bridge_sampler(m1)
bf_10 <- bridgesampling::bf(m1_bridge, m0_bridge)
samp <- rstan::extract(m1)
post <- mean(samp$bp<0 & samp$bl>0)
prior <- 0.5^2
bf_re <- post/prior
bf_r0 <- bf_10$bf * bf_re
bf_r0
mean(dat$deviation[dat$condition=='blinding' & dat$deviation > 0])
mean(dat$deviation[dat$condition=='preregistration' & dat$deviation > 0])
sum(dat$deviation[dat$condition == 'blinding'] == 0)
sum(dat$deviation[dat$condition == 'preregistration'] == 0)
p_nodeviation_prereg <- logistic(median(samp[['ap']]) + median(samp[['bp']])) # probability of deviation in preregistration condition
p_nodeviation_blinding <- logistic(median(samp[['ap']])) # probability of deviation in blinding condition
m_deviations_prereg <- exp(median(samp[['al']]) + median(samp[['bl']])) # mean number of deviations when deviated in preregistration condition
m_deviations_blinding <- exp(median(samp[['al']])) # mean number of deviations when deviated in blinding condition
p_nodeviation_prereg
p_nodeviation_blinding
m_deviations_prereg
m_deviations_blinding
p_nodeviation_prereg
p_nodeviation_blinding
m_deviations_prereg
m_deviations_blinding
bf_r0
bf_re <- post/prior
bf_re
bf_r0
38/100 * 75
38/100 * 80
46/100 * 75
46/100 * 80
54/100 * 80
54/100 * 75
dat <- data.frame(subj = 1:30,
resp = rnorm(30),
age  = sample(18:27, 30, replace = TRUE))
dat
setwd("~/Git_projects/HandsOnOpenScience/data")
setwd("~/Git_projects/HandsOnOpenScience/data")
write.table(dat, 'seconddata.txt'. header=TRUE)
write.table(dat, 'seconddata.txt', header=TRUE)
write.table(dat, 'seconddata.txt')
dat <- data.frame(subj = 1:30,
resp = rnorm(30),
age  = sample(18:27, 30, replace = TRUE))
write.table(dat, 'seconddata.txt')
dat <- data.frame(subj = 1:30,
resp = rnorm(30),
age  = sample(18:27, 30, replace = TRUE))
write.table(dat, 'thirddata.txt')
